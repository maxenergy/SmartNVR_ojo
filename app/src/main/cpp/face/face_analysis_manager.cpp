#include "face_analysis_manager.h"
#include "inspireface_wrapper.h"
#include "log4c.h"
#include <chrono>

FaceAnalysisManager::FaceAnalysisManager()
    : m_initialized(false)
    , m_inspireFaceInitialized(false)
    , m_frameCounter(0)
    , m_javaInspireFaceInstance(nullptr)
    , m_createImageStreamMethod(nullptr)
    , m_executeFaceTrackMethod(nullptr)
    , m_pipelineProcessMethod(nullptr)
    , m_getFaceAttributeMethod(nullptr)
    , m_releaseImageStreamMethod(nullptr) {

    // åˆ›å»ºInspireFaceç»„ä»¶
    m_inspireFaceSession.reset(new InspireFaceSession());
    m_imageProcessor.reset(new InspireFaceImageProcessor());
    m_faceDetector.reset(new InspireFaceDetector());

    LOGI("FaceAnalysisManager created");
}

FaceAnalysisManager::~FaceAnalysisManager() {
    release();
    LOGI("FaceAnalysisManager destroyed");
}

bool FaceAnalysisManager::initialize(const std::string& modelPath) {
    std::lock_guard<std::mutex> lock(m_mutex);
    
    if (m_initialized) {
        LOGW("FaceAnalysisManager already initialized");
        return true;
    }
    
    LOGI("Initializing FaceAnalysisManager with model: %s", modelPath.c_str());
    
    // åˆå§‹åŒ–é»˜è®¤é…ç½®
    m_config = FaceAnalysisConfig();
    
    // é‡ç½®æ€§èƒ½ç»Ÿè®¡
    m_performanceStats = PerformanceStats();
    
    // ğŸ”§ ä¿®å¤: ä½¿ç”¨çœŸå®çš„InspireFaceåˆå§‹åŒ–æµç¨‹
    if (!initializeInspireFace(modelPath)) {
        LOGE("Failed to initialize InspireFace with model path: %s", modelPath.c_str());
        m_initialized = false;
        m_inspireFaceInitialized = false;
        return false;
    }
    
    LOGI("âœ… InspireFace initialized successfully with real implementation");
    
    m_initialized = true;
    LOGI("FaceAnalysisManager initialized successfully");
    return true;
}

void FaceAnalysisManager::release() {
    std::lock_guard<std::mutex> lock(m_mutex);
    
    if (!m_initialized) return;
    
    LOGI("Releasing FaceAnalysisManager");
    
    // é‡Šæ”¾JNIèµ„æº
    releaseJNIResources();
    
    // é‡ç½®çŠ¶æ€
    m_initialized = false;
    m_inspireFaceInitialized = false;
    m_frameCounter = 0;
    
    LOGI("FaceAnalysisManager released");
}

bool FaceAnalysisManager::initializeInspireFace(AAssetManager* assetManager,
                                                const std::string& internalDataPath) {
    std::lock_guard<std::mutex> lock(m_mutex);

    if (m_initialized) {
        LOGW("FaceAnalysisManager already initialized");
        return true;
    }

    LOGI("Initializing FaceAnalysisManager with InspireFace models");

    // åˆå§‹åŒ–é»˜è®¤é…ç½®
    m_config = FaceAnalysisConfig();

    // é‡ç½®æ€§èƒ½ç»Ÿè®¡
    m_performanceStats = PerformanceStats();

    // åˆå§‹åŒ–InspireFaceåº“
    if (!InspireFaceUtils::initializeLibrary()) {
        LOGE("Failed to initialize InspireFace library");
        return false;
    }

    // åˆ›å»ºInspireFaceä¼šè¯
    m_inspireFaceSession.reset(new InspireFaceSession());
    if (!m_inspireFaceSession->initialize(assetManager, internalDataPath, true)) {
        LOGE("Failed to initialize InspireFace session");
        return false;
    }

    // åˆ›å»ºæ£€æµ‹å™¨å’Œå›¾åƒå¤„ç†å™¨
    m_faceDetector.reset(new InspireFaceDetector());
    m_imageProcessor.reset(new InspireFaceImageProcessor());

    if (!m_faceDetector->initialize(m_inspireFaceSession.get())) {
        LOGE("Failed to initialize InspireFace components");
        return false;
    }

    m_initialized = true;
    m_inspireFaceInitialized = true;
    LOGI("FaceAnalysisManager initialized successfully with InspireFace");
    return true;
}

bool FaceAnalysisManager::analyzePersonRegions(const cv::Mat& image,
                                              const std::vector<InferenceResult>& personDetections,
                                              std::vector<FaceAnalysisResult>& results) {
    std::lock_guard<std::mutex> lock(m_mutex);
    
    if (!m_initialized || !m_inspireFaceInitialized) {
        LOGW("FaceAnalysisManager not initialized");
        return false;
    }
    
    // æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ†æå½“å‰å¸§
    if (!shouldAnalyzeCurrentFrame()) {
        return true; // è·³è¿‡åˆ†æä½†è¿”å›æˆåŠŸ
    }
    
    auto startTime = std::chrono::steady_clock::now();
    
    results.clear();
    results.reserve(personDetections.size());
    
    LOGD("Analyzing %zu person regions", personDetections.size());
    
    bool overallSuccess = true;
    int successCount = 0;
    
    for (size_t i = 0; i < personDetections.size() && i < static_cast<size_t>(m_config.maxConcurrentAnalysis); ++i) {
        const auto& person = personDetections[i];
        
        // éªŒè¯äººå‘˜æ£€æµ‹ç»“æœ
        if (person.class_name != "person") continue;
        
        // è®¡ç®—äººå‘˜åŒºåŸŸ
        cv::Rect personRect(
            static_cast<int>(person.x1),
            static_cast<int>(person.y1),
            static_cast<int>(person.x2 - person.x1),
            static_cast<int>(person.y2 - person.y1)
        );
        
        // æ‰©å±•ROIåŒºåŸŸ
        personRect = expandROI(personRect, image.size());
        
        // è¾¹ç•Œæ£€æŸ¥
        personRect &= cv::Rect(0, 0, image.cols, image.rows);
        if (personRect.width < m_config.minFacePixelSize || 
            personRect.height < m_config.minFacePixelSize) {
            LOGD("Person region too small, skipping");
            continue;
        }
        
        // åˆ›å»ºäººè„¸åˆ†æç»“æœ
        FaceAnalysisResult faceResult;
        faceResult.personId = static_cast<int>(i);
        faceResult.personDetection = person;
        
        // æ‰§è¡Œäººè„¸åˆ†æ
        if (analyzePersonROI(image, personRect, faceResult)) {
            results.push_back(std::move(faceResult));
            successCount++;
        } else {
            overallSuccess = false;
            LOGW("Failed to analyze person region %zu", i);
        }
    }
    
    auto endTime = std::chrono::steady_clock::now();
    auto processingTime = std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime);
    
    // æ›´æ–°æ€§èƒ½ç»Ÿè®¡
    updatePerformanceStats(overallSuccess, processingTime);
    
    LOGD("Face analysis completed: %d/%zu successful, %lld ms", 
         successCount, personDetections.size(), processingTime.count());
    
    // è®°å½•åˆ†æç»“æœ
    if (!results.empty()) {
        logAnalysisResult(results[0]); // è®°å½•ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºç¤ºä¾‹
    }
    
    return overallSuccess;
}

void FaceAnalysisManager::setConfig(const FaceAnalysisConfig& config) {
    std::lock_guard<std::mutex> lock(m_mutex);
    
    if (!config.isValid()) {
        LOGE("Invalid FaceAnalysisConfig provided");
        return;
    }
    
    m_config = config;
    LOGI("FaceAnalysisConfig updated");
}

FaceAnalysisConfig FaceAnalysisManager::getConfig() const {
    std::lock_guard<std::mutex> lock(m_mutex);
    return m_config;
}

FaceAnalysisManager::PerformanceStats FaceAnalysisManager::getPerformanceStats() const {
    std::lock_guard<std::mutex> lock(m_mutex);
    return m_performanceStats;
}

void FaceAnalysisManager::resetPerformanceStats() {
    std::lock_guard<std::mutex> lock(m_mutex);
    m_performanceStats = PerformanceStats();
    LOGI("Performance stats reset");
}

bool FaceAnalysisManager::shouldAnalyzeCurrentFrame() {
    m_frameCounter++;
    return (m_frameCounter % m_config.analysisInterval) == 0;
}

// ==================== ç§æœ‰æ–¹æ³•å®ç° ====================

bool FaceAnalysisManager::initializeInspireFace(const std::string& modelPath) {
    LOGI("Initializing InspireFace with model: %s", modelPath.c_str());

    // åˆå§‹åŒ–InspireFaceåº“
    if (!InspireFaceUtils::initializeLibrary()) {
        LOGE("Failed to initialize InspireFace library");
        return false;
    }

    // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if (!InspireFaceUtils::checkModelFiles(modelPath)) {
        LOGE("Model files not found at: %s", modelPath.c_str());
        return false;
    }

    // ğŸ”§ ä¿®å¤: åˆ›å»ºå¹¶åˆå§‹åŒ–InspireFaceä¼šè¯
    m_inspireFaceSession.reset(new InspireFaceSession());
    
    // ğŸ”§ ä¿®å¤: ä½¿ç”¨æ ‡å‡†åˆå§‹åŒ–æ–¹æ³•ï¼ˆä¼ å…¥nullpträ½œä¸ºAssetManagerï¼Œä½¿ç”¨modelPathä½œä¸ºå†…éƒ¨è·¯å¾„ï¼‰
    if (!m_inspireFaceSession->initialize(nullptr, modelPath, true)) {
        LOGE("Failed to initialize InspireFace session with path: %s", modelPath.c_str());
        return false;
    }
    
    // åˆ›å»ºå›¾åƒå¤„ç†å™¨
    m_imageProcessor.reset(new InspireFaceImageProcessor());
    
    LOGI("âœ… InspireFace session and components created successfully");

    // åˆå§‹åŒ–æ£€æµ‹å™¨
    if (!m_faceDetector->initialize(m_inspireFaceSession.get())) {
        LOGE("Failed to initialize face detector");
        return false;
    }

    LOGI("InspireFace initialized successfully");
    return true;
}

bool FaceAnalysisManager::initializeJNIMethods() {
    // TODO: åˆå§‹åŒ–JNIæ–¹æ³•ID
    // è·å–InspireFaceç›¸å…³çš„æ–¹æ³•IDå¹¶ç¼“å­˜
    LOGD("JNI methods initialization placeholder");
    return true;
}

void FaceAnalysisManager::releaseJNIResources() {
    // TODO: é‡Šæ”¾JNIèµ„æº
    // é‡Šæ”¾å…¨å±€å¼•ç”¨å’Œå…¶ä»–JNIèµ„æº
    LOGD("JNI resources release placeholder");
    
    m_javaInspireFaceInstance = nullptr;
    m_createImageStreamMethod = nullptr;
    m_executeFaceTrackMethod = nullptr;
    m_pipelineProcessMethod = nullptr;
    m_getFaceAttributeMethod = nullptr;
    m_releaseImageStreamMethod = nullptr;
}

bool FaceAnalysisManager::analyzePersonROI(const cv::Mat& image,
                                          const cv::Rect& personRect,
                                          FaceAnalysisResult& result) {
    LOGD("Analyzing person ROI: [%d,%d,%d,%d]",
         personRect.x, personRect.y, personRect.width, personRect.height);

    // æå–äººå‘˜åŒºåŸŸ
    cv::Mat personROI = image(personRect);

    // 1. åˆ›å»ºå›¾åƒæµ
    void* imageStream = nullptr;
    if (!m_imageProcessor->createImageStreamFromMat(personROI, &imageStream)) {
        LOGE("Failed to create image stream from person ROI");
        return false;
    }

    // 2. æ‰§è¡Œäººè„¸æ£€æµ‹å’Œå±æ€§åˆ†æ
    std::vector<FaceDetectionResult> faceResults;
    std::vector<FaceAttributeResult> attributeResults;

    bool success = m_faceDetector->detectAndAnalyze(imageStream, faceResults, attributeResults);

    // 3. é‡Šæ”¾å›¾åƒæµ
    m_imageProcessor->releaseImageStream(imageStream);

    if (!success) {
        LOGE("Face detection and analysis failed");
        return false;
    }

    // 4. è½¬æ¢ç»“æœæ ¼å¼
    result.faces.clear();
    for (size_t i = 0; i < faceResults.size() && i < attributeResults.size(); ++i) {
        FaceInfo faceInfo;

        // è½¬æ¢äººè„¸ä½ç½®ï¼ˆç›¸å¯¹äºåŸå›¾åƒçš„åæ ‡ï¼‰
        faceInfo.faceRect = cv::Rect(
            personRect.x + faceResults[i].faceRect.x,
            personRect.y + faceResults[i].faceRect.y,
            faceResults[i].faceRect.width,
            faceResults[i].faceRect.height
        );
        faceInfo.confidence = faceResults[i].confidence;

        // è½¬æ¢å±æ€§ä¿¡æ¯
        faceInfo.attributes.gender = attributeResults[i].gender;
        faceInfo.attributes.genderConfidence = attributeResults[i].genderConfidence;
        faceInfo.attributes.ageBracket = attributeResults[i].ageBracket;
        faceInfo.attributes.ageConfidence = attributeResults[i].ageConfidence;
        faceInfo.attributes.race = attributeResults[i].race;
        faceInfo.attributes.raceConfidence = attributeResults[i].raceConfidence;

        result.faces.push_back(faceInfo);

        LOGD("Face %zu: %s, %s, conf=%.2f", i,
             attributeResults[i].getGenderString().c_str(),
             attributeResults[i].getAgeBracketString().c_str(),
             faceInfo.confidence);
    }

    LOGD("Person ROI analysis completed with %zu faces", result.faces.size());
    return true;
}

cv::Rect FaceAnalysisManager::expandROI(const cv::Rect& originalROI, 
                                       const cv::Size& imageSize) const {
    float expandRatio = m_config.roiExpandRatio;
    
    int expandX = static_cast<int>(originalROI.width * expandRatio);
    int expandY = static_cast<int>(originalROI.height * expandRatio);
    
    cv::Rect expandedROI(
        originalROI.x - expandX,
        originalROI.y - expandY,
        originalROI.width + 2 * expandX,
        originalROI.height + 2 * expandY
    );
    
    // ç¡®ä¿åœ¨å›¾åƒè¾¹ç•Œå†…
    expandedROI &= cv::Rect(0, 0, imageSize.width, imageSize.height);
    
    return expandedROI;
}

bool FaceAnalysisManager::convertMatToInspireFaceFormat(const cv::Mat& image, 
                                                       jobject& imageStream) {
    // TODO: å®ç°cv::Matåˆ°InspireFaceæ ¼å¼çš„è½¬æ¢
    LOGD("Converting cv::Mat to InspireFace format placeholder");
    return true;
}

bool FaceAnalysisManager::extractFaceAttributesFromJava(jobject faceAttributeResult,
                                                       std::vector<FaceInfo>& faces) {
    // TODO: ä»Javaå¯¹è±¡æå–äººè„¸å±æ€§ä¿¡æ¯
    LOGD("Extracting face attributes from Java placeholder");
    return true;
}

void FaceAnalysisManager::updatePerformanceStats(bool success, 
                                                 std::chrono::milliseconds processingTime) {
    m_performanceStats.totalAnalysisCount++;
    if (success) {
        m_performanceStats.successfulAnalysisCount++;
    }
    m_performanceStats.totalProcessingTime += processingTime;
    m_performanceStats.lastAnalysisTime = std::chrono::steady_clock::now();
}

void FaceAnalysisManager::logAnalysisResult(const FaceAnalysisResult& result) const {
    LOGD("Face analysis result for person %d:", result.personId);
    LOGD("  Person detection: [%.1f,%.1f,%.1f,%.1f] conf=%.2f", 
         result.personDetection.x1, result.personDetection.y1,
         result.personDetection.x2, result.personDetection.y2,
         result.personDetection.confidence);
    
    for (size_t i = 0; i < result.faces.size(); ++i) {
        const auto& face = result.faces[i];
        LOGD("  Face %zu: [%d,%d,%d,%d] conf=%.2f", i,
             face.faceRect.x, face.faceRect.y, 
             face.faceRect.width, face.faceRect.height,
             face.confidence);
        
        if (face.attributes.isValid()) {
            LOGD("    Gender: %s (%.2f)", face.attributes.getGenderString().c_str(),
                 face.attributes.genderConfidence);
            LOGD("    Age: %s (%.2f)", face.attributes.getAgeBracketString().c_str(),
                 face.attributes.ageConfidence);
        }
    }
}

void FaceAnalysisManager::logPerformanceStats() const {
    const auto& stats = m_performanceStats;
    LOGI("Face Analysis Performance Stats:");
    LOGI("  Total analyses: %d", stats.totalAnalysisCount);
    LOGI("  Successful: %d (%.1f%%)", stats.successfulAnalysisCount,
         stats.getSuccessRate());
    LOGI("  Average time: %.1f ms", stats.getAverageProcessingTime());
}

// ==================== å·¥å…·å‡½æ•°å®ç° ====================

namespace FaceAnalysisUtils {

std::vector<InferenceResult> filterPersonDetections(
    const std::vector<InferenceResult>& allDetections,
    float confidenceThreshold,
    int minPixelSize) {
    
    std::vector<InferenceResult> personDetections;
    
    for (const auto& detection : allDetections) {
        if (detection.class_name == "person" && 
            detection.confidence >= confidenceThreshold) {
            
            float width = detection.x2 - detection.x1;
            float height = detection.y2 - detection.y1;
            
            if (width >= minPixelSize && height >= minPixelSize) {
                personDetections.push_back(detection);
            }
        }
    }
    
    return personDetections;
}

bool isValidPersonROI(const cv::Rect& roi, const cv::Size& imageSize) {
    return roi.x >= 0 && roi.y >= 0 && 
           roi.x + roi.width <= imageSize.width &&
           roi.y + roi.height <= imageSize.height &&
           roi.width > 0 && roi.height > 0;
}

cv::Rect convertFaceRectToImageCoords(const cv::Rect& faceRect,
                                     const cv::Rect& personROI) {
    return cv::Rect(
        personROI.x + faceRect.x,
        personROI.y + faceRect.y,
        faceRect.width,
        faceRect.height
    );
}

std::pair<int, int> countGenderDistribution(
    const std::vector<FaceAnalysisResult>& results) {
    
    int maleCount = 0, femaleCount = 0;
    
    for (const auto& result : results) {
        for (const auto& face : result.faces) {
            if (face.attributes.gender == 1) maleCount++;
            else if (face.attributes.gender == 0) femaleCount++;
        }
    }
    
    return {maleCount, femaleCount};
}

std::vector<int> countAgeBracketDistribution(
    const std::vector<FaceAnalysisResult>& results) {
    
    std::vector<int> ageCounts(9, 0);
    
    for (const auto& result : results) {
        for (const auto& face : result.faces) {
            if (face.attributes.ageBracket >= 0 && face.attributes.ageBracket < 9) {
                ageCounts[face.attributes.ageBracket]++;
            }
        }
    }
    
    return ageCounts;
}

cv::Mat drawFaceAnalysisResults(const cv::Mat& image,
                               const std::vector<FaceAnalysisResult>& results) {
    cv::Mat resultImage = image.clone();
    
    for (const auto& result : results) {
        // ç»˜åˆ¶äººå‘˜è¾¹ç•Œæ¡†
        cv::Rect personRect(
            static_cast<int>(result.personDetection.x1),
            static_cast<int>(result.personDetection.y1),
            static_cast<int>(result.personDetection.x2 - result.personDetection.x1),
            static_cast<int>(result.personDetection.y2 - result.personDetection.y1)
        );
        cv::rectangle(resultImage, personRect, cv::Scalar(0, 255, 0), 2);
        
        // ç»˜åˆ¶äººè„¸ä¿¡æ¯
        for (const auto& face : result.faces) {
            cv::Rect faceRect = convertFaceRectToImageCoords(face.faceRect, personRect);
            cv::rectangle(resultImage, faceRect, cv::Scalar(255, 0, 0), 1);
            
            if (face.attributes.isValid()) {
                std::string text = face.attributes.getGenderString() + " " + 
                                 face.attributes.getAgeBracketString();
                cv::putText(resultImage, text, 
                           cv::Point(faceRect.x, faceRect.y - 5),
                           cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 255, 0), 1);
            }
        }
    }
    
    return resultImage;
}

} // namespace FaceAnalysisUtils

// ç®€åŒ–çš„äººè„¸åˆ†ææ¥å£å®ç° (ç”¨äºJNIè°ƒç”¨)
bool FaceAnalysisManager::analyzeFaces(const cv::Mat& image, 
                                      const std::vector<PersonDetection>& personDetections,
                                      SimpleFaceAnalysisResult& result) {
    std::lock_guard<std::mutex> lock(m_mutex);
    
    if (!m_initialized) {
        result.success = false;
        result.errorMessage = "FaceAnalysisManager not initialized";
        return false;
    }
    
    LOGI("å¼€å§‹åˆ†æ %zu ä¸ªäººå‘˜åŒºåŸŸçš„äººè„¸", personDetections.size());
    
    // é‡ç½®ç»“æœ
    result.success = false;
    result.faceCount = 0;
    result.maleCount = 0;
    result.femaleCount = 0;
    memset(result.ageGroups, 0, sizeof(result.ageGroups));
    result.faces.clear();
    
    if (personDetections.empty()) {
        LOGW("æ²¡æœ‰äººå‘˜æ£€æµ‹ç»“æœï¼Œè·³è¿‡äººè„¸åˆ†æ");
        result.success = true;
        return true;
    }
    
    try {
        // è½¬æ¢PersonDetectionåˆ°InferenceResultæ ¼å¼
        std::vector<InferenceResult> inferenceResults;
        for (const auto& person : personDetections) {
            InferenceResult inference;
            inference.x1 = person.x1;
            inference.y1 = person.y1;
            inference.x2 = person.x2;
            inference.y2 = person.y2;
            inference.confidence = person.confidence;
            inference.class_name = "person";
            inferenceResults.push_back(inference);
        }
        
        // ä½¿ç”¨ç°æœ‰çš„analyzePersonRegionsæ–¹æ³•
        std::vector<FaceAnalysisResult> analysisResults;
        bool success = analyzePersonRegions(image, inferenceResults, analysisResults);
        
        if (!success) {
            result.errorMessage = "äººè„¸åˆ†æå¤±è´¥";
            return false;
        }
        
        // æ±‡æ€»ç»“æœ
        for (const auto& analysisResult : analysisResults) {
            for (const auto& faceInfo : analysisResult.faces) {
                if (faceInfo.attributes.isValid()) {
                    result.faceCount++;
                    
                    // ç»Ÿè®¡æ€§åˆ«
                    if (faceInfo.attributes.gender == 1) {
                        result.maleCount++;
                    } else if (faceInfo.attributes.gender == 0) {
                        result.femaleCount++;
                    }
                    
                    // ç»Ÿè®¡å¹´é¾„ç»„
                    if (faceInfo.attributes.ageBracket >= 0 && faceInfo.attributes.ageBracket < 9) {
                        result.ageGroups[faceInfo.attributes.ageBracket]++;
                    }
                    
                    // æ·»åŠ äººè„¸ä¿¡æ¯
                    SimpleFaceAnalysisResult::Face face;
                    face.x1 = static_cast<float>(faceInfo.faceRect.x);
                    face.y1 = static_cast<float>(faceInfo.faceRect.y);
                    face.x2 = static_cast<float>(faceInfo.faceRect.x + faceInfo.faceRect.width);
                    face.y2 = static_cast<float>(faceInfo.faceRect.y + faceInfo.faceRect.height);
                    face.confidence = faceInfo.confidence;
                    face.gender = faceInfo.attributes.gender;
                    face.age = faceInfo.attributes.ageBracket;
                    
                    result.faces.push_back(face);
                }
            }
        }
        
        result.success = true;
        LOGI("âœ… äººè„¸åˆ†æå®Œæˆ: %d ä¸ªäººè„¸, %d ç”·æ€§, %d å¥³æ€§", 
             result.faceCount, result.maleCount, result.femaleCount);
        
        return true;
        
    } catch (const std::exception& e) {
        result.success = false;
        result.errorMessage = std::string("äººè„¸åˆ†æå¼‚å¸¸: ") + e.what();
        LOGE("äººè„¸åˆ†æå¼‚å¸¸: %s", e.what());
        return false;
    }
}
